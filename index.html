<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Genesis - AI Evolution Laboratory</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;700;900&family=Inter:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #00f5ff;
            --secondary: #bf00ff;
            --accent: #ff00aa;
            --green: #00ff88;
            --orange: #ff8800;
            --dark: #0a0a15;
            --darker: #050508;
            --glass: rgba(255, 255, 255, 0.04);
            --glass-border: rgba(255, 255, 255, 0.1);
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: 'Inter', sans-serif;
            background: var(--darker);
            color: #fff;
            overflow-x: hidden;
            line-height: 1.6;
        }

        /* â”€â”€ Background â”€â”€ */
        .bg-animation {
            position: fixed; top: 0; left: 0;
            width: 100%; height: 100%; z-index: -1; overflow: hidden;
        }
        .bg-animation::before {
            content: '';
            position: absolute; top: -50%; left: -50%;
            width: 200%; height: 200%;
            background:
                radial-gradient(circle at 20% 80%, rgba(0, 245, 255, 0.07) 0%, transparent 50%),
                radial-gradient(circle at 80% 20%, rgba(191, 0, 255, 0.07) 0%, transparent 50%),
                radial-gradient(circle at 40% 40%, rgba(255, 0, 170, 0.04) 0%, transparent 40%);
            animation: bgRotate 30s linear infinite;
        }
        @keyframes bgRotate {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .neural-bg { position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: -1; opacity: 0.08; }
        .neural-node {
            position: absolute; width: 4px; height: 4px;
            background: var(--primary); border-radius: 50%;
            animation: pulse 2s ease-in-out infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 0.3; transform: scale(1); }
            50% { opacity: 1; transform: scale(1.5); }
        }

        /* â”€â”€ Header â”€â”€ */
        header {
            position: fixed; top: 0; width: 100%;
            padding: 1.2rem 5%;
            display: flex; justify-content: space-between; align-items: center;
            z-index: 1000;
            background: rgba(5, 5, 8, 0.85);
            backdrop-filter: blur(20px);
            border-bottom: 1px solid var(--glass-border);
        }
        .logo {
            font-family: 'Orbitron', sans-serif; font-size: 1.6rem; font-weight: 900;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }
        nav a {
            color: rgba(255,255,255,0.75); text-decoration: none;
            margin-left: 1.8rem; font-size: 0.88rem; font-weight: 500;
            transition: all 0.3s ease; position: relative;
        }
        nav a::after {
            content: ''; position: absolute; bottom: -4px; left: 0;
            width: 0; height: 2px; background: var(--primary); transition: width 0.3s ease;
        }
        nav a:hover::after { width: 100%; }
        nav a:hover { color: var(--primary); }

        /* â”€â”€ Shared â”€â”€ */
        .glass-card {
            background: var(--glass);
            backdrop-filter: blur(20px);
            border: 1px solid var(--glass-border);
            border-radius: 16px; padding: 2rem;
            transition: all 0.3s ease;
        }
        .glass-card:hover {
            border-color: rgba(0, 245, 255, 0.3);
            box-shadow: 0 0 40px rgba(0, 245, 255, 0.06);
            transform: translateY(-3px);
        }
        section { padding: 6rem 5%; }
        .section-header { text-align: center; margin-bottom: 3.5rem; }
        .section-header h2 {
            font-family: 'Orbitron', sans-serif; font-size: 2.2rem; margin-bottom: 0.8rem;
            background: linear-gradient(135deg, #fff, var(--primary));
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }
        .section-header p { color: rgba(255,255,255,0.55); max-width: 620px; margin: 0 auto; }

        .tag {
            display: inline-block; padding: 0.25rem 0.75rem; border-radius: 50px;
            font-size: 0.72rem; font-weight: 600; letter-spacing: 0.05em;
            text-transform: uppercase;
        }
        .tag-done { background: rgba(0,255,136,0.12); color: var(--green); border: 1px solid rgba(0,255,136,0.3); }
        .tag-wip  { background: rgba(255,136,0,0.12); color: var(--orange); border: 1px solid rgba(255,136,0,0.3); }
        .tag-next { background: rgba(191,0,255,0.12); color: #d070ff; border: 1px solid rgba(191,0,255,0.3); }

        /* â”€â”€ Hero â”€â”€ */
        .hero {
            min-height: 100vh; display: flex; align-items: center;
            justify-content: center; padding: 9rem 5% 5rem; position: relative;
        }
        .hero-content { text-align: center; max-width: 900px; }
        .hero h1 {
            font-family: 'Orbitron', sans-serif;
            font-size: clamp(2.2rem, 7vw, 4.5rem);
            font-weight: 900; margin-bottom: 1.5rem; line-height: 1.1;
        }
        .hero h1 span {
            background: linear-gradient(135deg, var(--primary), var(--secondary), var(--accent));
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
            animation: gradientShift 5s ease infinite; background-size: 200% 200%;
        }
        @keyframes gradientShift {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }
        .hero p { font-size: 1.15rem; color: rgba(255,255,255,0.65); margin-bottom: 2.5rem; max-width: 700px; margin-left: auto; margin-right: auto; }

        /* live stat badges in hero */
        .hero-stats {
            display: flex; justify-content: center; gap: 2rem; flex-wrap: wrap;
            margin-bottom: 2.5rem;
        }
        .hero-stat {
            background: var(--glass); border: 1px solid var(--glass-border);
            border-radius: 12px; padding: 1rem 1.8rem; text-align: center;
        }
        .hero-stat .val {
            font-family: 'Orbitron', sans-serif; font-size: 1.8rem;
            font-weight: 700; color: var(--primary);
        }
        .hero-stat .lbl { font-size: 0.78rem; color: rgba(255,255,255,0.5); margin-top: 0.2rem; }

        .cta-buttons { display: flex; gap: 1.2rem; justify-content: center; flex-wrap: wrap; }
        .btn {
            padding: 0.9rem 2.2rem; border-radius: 50px; font-weight: 600;
            text-decoration: none; transition: all 0.3s ease; font-size: 0.95rem;
            display: inline-flex; align-items: center; gap: 0.5rem;
        }
        .btn-primary {
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: var(--darker); box-shadow: 0 0 30px rgba(0,245,255,0.25);
        }
        .btn-primary:hover { transform: translateY(-3px); box-shadow: 0 0 50px rgba(0,245,255,0.45); }
        .btn-secondary {
            background: transparent; color: #fff;
            border: 1px solid var(--glass-border);
        }
        .btn-secondary:hover { border-color: var(--primary); color: var(--primary); }

        /* â”€â”€ Results Banner â”€â”€ */
        .results-banner {
            background: linear-gradient(135deg, rgba(0,245,255,0.05), rgba(191,0,255,0.05));
            border-top: 1px solid rgba(0,245,255,0.15);
            border-bottom: 1px solid rgba(191,0,255,0.15);
            padding: 3rem 5%;
        }
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
            gap: 2rem; max-width: 1100px; margin: 0 auto;
            text-align: center;
        }
        .result-item .number {
            font-family: 'Orbitron', sans-serif; font-size: 2.5rem; font-weight: 900;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }
        .result-item .label {
            font-size: 0.82rem; color: rgba(255,255,255,0.5);
            margin-top: 0.3rem; text-transform: uppercase; letter-spacing: 0.05em;
        }
        .result-item .sub {
            font-size: 0.75rem; color: rgba(255,255,255,0.3); margin-top: 0.15rem;
        }

        /* â”€â”€ Pipeline â”€â”€ */
        .pipeline {
            display: flex; flex-direction: column; gap: 0;
            max-width: 900px; margin: 0 auto;
        }
        .pipeline-step {
            display: grid; grid-template-columns: 60px 1fr;
            gap: 1.5rem; position: relative;
        }
        .pipeline-step:not(:last-child) .step-line {
            position: absolute; left: 30px; top: 60px; bottom: -1px;
            width: 2px;
            background: linear-gradient(180deg, var(--primary), var(--secondary));
        }
        .step-num {
            width: 60px; height: 60px; border-radius: 50%;
            background: var(--glass); border: 2px solid var(--primary);
            display: flex; align-items: center; justify-content: center;
            font-family: 'Orbitron', sans-serif; font-size: 1.1rem; font-weight: 700;
            color: var(--primary); flex-shrink: 0;
            box-shadow: 0 0 20px rgba(0,245,255,0.2);
        }
        .step-body { padding-bottom: 2.5rem; }
        .step-body h3 {
            font-family: 'Orbitron', sans-serif; font-size: 1.1rem;
            color: var(--primary); margin-bottom: 0.6rem;
            display: flex; align-items: center; gap: 0.8rem;
        }
        .step-body p { color: rgba(255,255,255,0.65); font-size: 0.92rem; margin-bottom: 0.6rem; }
        .step-body .insight {
            background: rgba(0,245,255,0.05); border-left: 3px solid var(--primary);
            padding: 0.6rem 1rem; border-radius: 0 8px 8px 0;
            font-size: 0.82rem; color: rgba(255,255,255,0.55);
            font-family: 'JetBrains Mono', monospace; margin-top: 0.6rem;
        }
        .step-body .warning {
            background: rgba(255,136,0,0.07); border-left: 3px solid var(--orange);
            padding: 0.6rem 1rem; border-radius: 0 8px 8px 0;
            font-size: 0.82rem; color: rgba(255,200,100,0.8);
            margin-top: 0.6rem;
        }

        /* â”€â”€ Architecture â”€â”€ */
        .architecture {
            background: linear-gradient(180deg, transparent, rgba(0,245,255,0.02), transparent);
        }
        .arch-diagram { max-width: 1000px; margin: 0 auto; }
        .gpu-container {
            display: grid; grid-template-columns: 1fr auto 1fr;
            gap: 2rem; align-items: center; margin-bottom: 2rem;
        }
        .gpu-box {
            border-radius: 15px; padding: 2rem; text-align: center;
            background: var(--glass); border: 1px solid var(--glass-border);
        }
        .gpu-box h3 { font-family: 'Orbitron', sans-serif; margin-bottom: 1rem; font-size: 0.95rem; }
        .gpu-box.teacher { border-color: var(--primary); box-shadow: 0 0 30px rgba(0,245,255,0.08); }
        .gpu-box.teacher h3 { color: var(--primary); }
        .gpu-box.student { border-color: var(--secondary); box-shadow: 0 0 30px rgba(191,0,255,0.08); }
        .gpu-box.student h3 { color: #d070ff; }
        .gpu-box p { font-size: 0.82rem; color: rgba(255,255,255,0.55); margin: 0.25rem 0; }
        .gpu-mem {
            margin-top: 1rem; padding: 0.5rem; border-radius: 8px;
            background: rgba(0,0,0,0.3); font-family: 'JetBrains Mono', monospace;
            font-size: 0.75rem; color: rgba(255,255,255,0.4);
        }
        .arrow-container { display: flex; flex-direction: column; align-items: center; gap: 0.8rem; }
        .arrow {
            width: 60px; height: 2px;
            background: linear-gradient(90deg, var(--primary), var(--secondary));
            position: relative;
        }
        .arrow::after {
            content: ''; position: absolute; right: -8px; top: -4px;
            border: 5px solid transparent; border-left-color: var(--secondary);
        }
        .arrow-label { color: rgba(255,255,255,0.4); font-size: 0.72rem; text-align: center; }

        .arch-note {
            max-width: 1000px; margin: 1.5rem auto 0;
            background: rgba(255,136,0,0.06); border: 1px solid rgba(255,136,0,0.2);
            border-radius: 10px; padding: 1rem 1.5rem;
            font-size: 0.83rem; color: rgba(255,200,100,0.75);
            display: flex; align-items: flex-start; gap: 0.8rem;
        }
        .arch-note span { flex-shrink: 0; font-size: 1rem; }

        /* â”€â”€ Results Table â”€â”€ */
        .runs-table { width: 100%; border-collapse: collapse; max-width: 900px; margin: 0 auto; }
        .runs-table th {
            font-family: 'Orbitron', sans-serif; font-size: 0.75rem; font-weight: 600;
            color: var(--primary); text-align: left; padding: 0.8rem 1.2rem;
            border-bottom: 1px solid rgba(0,245,255,0.2);
            text-transform: uppercase; letter-spacing: 0.05em;
        }
        .runs-table td {
            padding: 0.9rem 1.2rem; font-size: 0.88rem;
            border-bottom: 1px solid rgba(255,255,255,0.05);
            color: rgba(255,255,255,0.75);
            font-family: 'JetBrains Mono', monospace;
        }
        .runs-table tr:hover td { background: rgba(0,245,255,0.03); }
        .val-good { color: var(--green); }
        .val-base { color: rgba(255,255,255,0.45); }

        /* â”€â”€ Tech Grid â”€â”€ */
        .tech-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
            gap: 1.5rem; max-width: 1200px; margin: 0 auto;
        }
        .tech-card { text-align: center; padding: 2rem; }
        .tech-icon { font-size: 2.5rem; margin-bottom: 0.8rem; display: block; }
        .tech-card h3 { font-family: 'Orbitron', sans-serif; font-size: 0.95rem; margin-bottom: 0.5rem; color: var(--primary); }
        .tech-card p { font-size: 0.85rem; color: rgba(255,255,255,0.55); }

        /* â”€â”€ Fixes / Insights â”€â”€ */
        .fixes-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 1.5rem; max-width: 1200px; margin: 0 auto;
        }
        .fix-card { padding: 1.5rem; }
        .fix-card .fix-title {
            font-family: 'Orbitron', sans-serif; font-size: 0.9rem;
            color: var(--green); margin-bottom: 0.5rem;
            display: flex; align-items: center; gap: 0.6rem;
        }
        .fix-card .fix-title .badge {
            font-size: 0.65rem; padding: 0.15rem 0.5rem;
            background: rgba(0,255,136,0.12); border-radius: 4px;
            color: var(--green); text-transform: uppercase;
        }
        .fix-card p { font-size: 0.85rem; color: rgba(255,255,255,0.55); }
        .fix-card code {
            display: block; margin-top: 0.6rem;
            background: rgba(0,0,0,0.4); border-radius: 6px;
            padding: 0.6rem 0.9rem; font-family: 'JetBrains Mono', monospace;
            font-size: 0.75rem; color: rgba(0,245,255,0.7);
            border-left: 2px solid rgba(0,245,255,0.3);
            white-space: pre-wrap; word-break: break-all;
        }

        /* â”€â”€ Hardware Specs â”€â”€ */
        .specs-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5rem; max-width: 1000px; margin: 0 auto;
        }
        .spec-item { display: flex; align-items: center; gap: 1rem; padding: 1.5rem; }
        .spec-icon { font-size: 2rem; color: var(--primary); }
        .spec-info h4 { font-family: 'Orbitron', sans-serif; font-size: 0.85rem; margin-bottom: 0.25rem; }
        .spec-info p { color: rgba(255,255,255,0.55); font-size: 0.82rem; }

        /* â”€â”€ Roadmap â”€â”€ */
        .roadmap-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5rem; max-width: 1200px; margin: 0 auto 3rem;
        }
        .roadmap-card { padding: 1.8rem; }
        .roadmap-card .phase {
            font-family: 'Orbitron', sans-serif; font-size: 0.7rem;
            color: rgba(255,255,255,0.3); text-transform: uppercase;
            letter-spacing: 0.08em; margin-bottom: 0.4rem;
        }
        .roadmap-card h3 { font-family: 'Orbitron', sans-serif; font-size: 1rem; margin-bottom: 0.8rem; }
        .roadmap-card h3.done { color: var(--green); }
        .roadmap-card h3.wip  { color: var(--orange); }
        .roadmap-card h3.next { color: #d070ff; }
        .roadmap-card ul { list-style: none; }
        .roadmap-card li {
            padding: 0.35rem 0; font-size: 0.85rem;
            color: rgba(255,255,255,0.55);
            display: flex; align-items: flex-start; gap: 0.5rem;
        }
        .roadmap-card li::before { content: 'â€º'; color: inherit; flex-shrink: 0; }
        .roadmap-card li.done { color: rgba(0,255,136,0.75); }
        .roadmap-card li.done::before { content: 'âœ“'; }
        .roadmap-card li.wip  { color: rgba(255,180,80,0.8); }
        .roadmap-card li.wip::before  { content: 'âŸ³'; }

        /* â”€â”€ Next Steps â”€â”€ */
        .next-steps-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 1.5rem; max-width: 1200px; margin: 0 auto;
        }
        .next-card { padding: 1.8rem; }
        .next-card .priority {
            font-size: 0.7rem; text-transform: uppercase; letter-spacing: 0.08em;
            margin-bottom: 0.6rem;
        }
        .next-card h3 { font-family: 'Orbitron', sans-serif; font-size: 1rem; color: #d070ff; margin-bottom: 0.7rem; }
        .next-card p { font-size: 0.85rem; color: rgba(255,255,255,0.55); }
        .next-card .impact {
            margin-top: 1rem; font-size: 0.78rem;
            color: rgba(0,245,255,0.6);
            font-family: 'JetBrains Mono', monospace;
        }

        /* â”€â”€ Status legend â”€â”€ */
        .status-grid { display: flex; justify-content: center; gap: 2.5rem; flex-wrap: wrap; margin-top: 2.5rem; }
        .status-item { text-align: center; font-size: 0.85rem; display: flex; align-items: center; gap: 0.5rem; }
        .status-dot {
            width: 10px; height: 10px; border-radius: 50%;
            display: inline-block; animation: statusPulse 2s ease-in-out infinite;
        }
        .status-dot.active { background: var(--green); box-shadow: 0 0 10px var(--green); }
        .status-dot.wip    { background: var(--orange); box-shadow: 0 0 10px var(--orange); }
        .status-dot.next   { background: #d070ff; box-shadow: 0 0 10px #d070ff; }
        @keyframes statusPulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.4; } }

        /* â”€â”€ Footer â”€â”€ */
        footer { padding: 4rem 5% 2rem; border-top: 1px solid var(--glass-border); text-align: center; }
        .footer-links { display: flex; justify-content: center; gap: 2rem; margin-bottom: 2rem; flex-wrap: wrap; }
        .footer-links a { color: rgba(255,255,255,0.5); text-decoration: none; transition: color 0.3s ease; font-size: 0.88rem; }
        .footer-links a:hover { color: var(--primary); }
        .footer-copyright { color: rgba(255,255,255,0.3); font-size: 0.82rem; }

        /* â”€â”€ Responsive â”€â”€ */
        @media (max-width: 768px) {
            nav { display: none; }
            .gpu-container { grid-template-columns: 1fr; }
            .arrow-container { transform: rotate(90deg); }
        }

        /* â”€â”€ Scrollbar â”€â”€ */
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-track { background: var(--darker); }
        ::-webkit-scrollbar-thumb {
            background: linear-gradient(180deg, var(--primary), var(--secondary));
            border-radius: 3px;
        }
    </style>
</head>
<body>
    <div class="bg-animation"></div>
    <div class="neural-bg" id="neuralBg"></div>

    <!-- Header -->
    <header>
        <div class="logo">GENESIS</div>
        <nav>
            <a href="#pipeline">Pipeline</a>
            <a href="#architecture">Architecture</a>
            <a href="#results">Results</a>
            <a href="#fixes">Internals</a>
            <a href="#roadmap">Roadmap</a>
            <a href="#next">Next Steps</a>
            <a href="https://github.com/genesis-ai/genesis">GitHub</a>
        </nav>
    </header>

    <!-- Hero -->
    <section class="hero">
        <div class="hero-content">
            <h1><span>AI Evolution Laboratory</span></h1>
            <p>Evolutionary optimization of language model LoRA adapters through knowledge distillation,
            genetic crossover, and tournament selection â€” achieving measurable perplexity reduction
            on a 1.7B-parameter student model.</p>

            <div class="hero-stats">
                <div class="hero-stat">
                    <div class="val">âˆ’48%</div>
                    <div class="lbl">Perplexity Reduction</div>
                </div>
                <div class="hero-stat">
                    <div class="val">154â†’80</div>
                    <div class="lbl">PPL (Base â†’ Evolved)</div>
                </div>
                <div class="hero-stat">
                    <div class="val">0.0123</div>
                    <div class="lbl">Best Fitness Score</div>
                </div>
                <div class="hero-stat">
                    <div class="val">20</div>
                    <div class="lbl">Evolution Generations</div>
                </div>
            </div>

            <div class="cta-buttons">
                <a href="#pipeline" class="btn btn-primary">How It Works</a>
                <a href="#results" class="btn btn-secondary">View Results</a>
            </div>
        </div>
    </section>

    <!-- Results Banner -->
    <div class="results-banner">
        <div class="results-grid">
            <div class="result-item">
                <div class="number">Qwen3-1.7B</div>
                <div class="label">Student Model</div>
                <div class="sub">LoRA r=16, Î±=32</div>
            </div>
            <div class="result-item">
                <div class="number">qwen3.5</div>
                <div class="label">Teacher via Ollama</div>
                <div class="sub">Remote API, hard-label CE</div>
            </div>
            <div class="result-item">
                <div class="number">200</div>
                <div class="label">Distillation Steps</div>
                <div class="sub">Best eval loss 4.6465</div>
            </div>
            <div class="result-item">
                <div class="number">6</div>
                <div class="label">Population Size</div>
                <div class="sub">Elite 2, mutation 30%</div>
            </div>
            <div class="result-item">
                <div class="number">25 MB</div>
                <div class="label">Adapter Size</div>
                <div class="sub">q/k/v/o_proj, float32</div>
            </div>
            <div class="result-item">
                <div class="number">~80 PPL</div>
                <div class="label">Best Evolved PPL</div>
                <div class="sub">vs 154 base model</div>
            </div>
        </div>
    </div>

    <!-- Pipeline -->
    <section id="pipeline">
        <div class="section-header">
            <h2>How It Works</h2>
            <p>A two-phase training pipeline: knowledge distillation seeds the population,
            then evolutionary algorithms refine LoRA adapter weights across generations.</p>
        </div>

        <div class="pipeline">

            <div class="pipeline-step">
                <div class="step-line"></div>
                <div class="step-num">1</div>
                <div class="step-body glass-card">
                    <h3>Teacher Setup <span class="tag tag-done">Done</span></h3>
                    <p>An <strong>OllamaTeacher</strong> connects to a remote Ollama server and probes
                    whether the endpoint supports per-token logprobs. If supported, full soft-target
                    Knowledge Distillation (KL divergence + cross-entropy) is used. If not â€” as is
                    currently the case with Ollama's <code>/v1/completions</code> API â€” the trainer
                    automatically falls back to hard-label cross-entropy only.</p>
                    <div class="warning">
                        âš  Ollama's API returns <code>top_logprobs entries: 0</code> regardless of the
                        <code>logprobs=True</code> parameter. Without logprobs, soft targets are all uniform
                        â€” training toward them actively corrupts the student. The fallback is mandatory, not optional.
                    </div>
                    <div class="insight">logprobs probe â†’ NOT SUPPORTED â†’ hard-label CE only</div>
                </div>
            </div>

            <div class="pipeline-step">
                <div class="step-line"></div>
                <div class="step-num">2</div>
                <div class="step-body glass-card">
                    <h3>Knowledge Distillation <span class="tag tag-done">Done</span></h3>
                    <p>The student (<strong>Qwen3-1.7B + LoRA</strong>) trains against teacher completions
                    using hard-label cross-entropy. Labels are masked at padding positions
                    (<code>-100</code>) so the model is never penalized for pad tokens. Gradient
                    accumulation (Ã—4), cosine LR decay with linear warmup, and BF16 mixed precision
                    keep memory usage manageable on a single 32 GB GPU.</p>
                    <div class="insight">200 steps Â· lr=2e-5 Â· warmup=20 Â· eval every 40 steps â†’ best eval loss: 4.6465</div>
                </div>
            </div>

            <div class="pipeline-step">
                <div class="step-line"></div>
                <div class="step-num">3</div>
                <div class="step-body glass-card">
                    <h3>Population Initialization <span class="tag tag-done">Done</span></h3>
                    <p>After distillation, a <strong>Population</strong> of N individuals is created.
                    Individual 0 copies the distilled LoRA weights exactly. Individuals 1â€¦N-1 are
                    Gaussian-mutated variants. All LoRA A/B tensors are kept on <strong>CPU</strong>
                    throughout evolution â€” only moved to GPU for fitness evaluation â€” preventing OOM
                    when handling large populations.</p>
                    <div class="insight">population size=6 Â· elite=2 Â· mutation_scale=0.05 Â· mutation_rate=0.3</div>
                </div>
            </div>

            <div class="pipeline-step">
                <div class="step-line"></div>
                <div class="step-num">4</div>
                <div class="step-body glass-card">
                    <h3>Fitness Evaluation <span class="tag tag-done">Done</span></h3>
                    <p>Each individual's LoRA weights are injected into the base model and evaluated
                    on a held-out WikiText-2 slice. <strong>Fitness = 1 / (1 + PPL)</strong> â€” higher
                    is better. Adapter loading uses CPU-first allocation
                    (<code>safetensors â†’ CPU â†’ GPU</code>) to avoid OOM on GPUs partially occupied by
                    Ollama. Keys are remapped from PEFT's saved format
                    (<code>lora_A.weight</code>) to the runtime format
                    (<code>lora_A.default.weight</code>).</p>
                    <div class="insight">fitness = 1/(1+ppl) Â· best: 0.0123 â†’ ppl â‰ˆ 80.3</div>
                </div>
            </div>

            <div class="pipeline-step">
                <div class="step-line"></div>
                <div class="step-num">5</div>
                <div class="step-body glass-card">
                    <h3>Genetic Evolution <span class="tag tag-done">Done</span></h3>
                    <p>Tournament selection picks parents; <strong>TIES-Merging crossover</strong>
                    (Yadav et al., 2023) resolves sign interference between LoRA adapters via
                    Trim â†’ Elect Sign â†’ Disjoint Merge. SLERP is also available as an alternative.
                    Gaussian mutation injects variation. Elite individuals (top-2) pass unchanged.
                    <strong>Lamarckian micro-training</strong> runs <code>memetic_steps</code>
                    gradient steps per individual before evaluation, writing locally-improved
                    weights back to the genome so descendants inherit the gradient refinement.</p>
                    <div class="insight">TIES density=0.2 Â· tournament_k=3 Â· mutate(Ïƒ=0.05, p=0.3) Â· memetic_steps=0 (configurable) Â· 20 gen</div>
                </div>
            </div>

            <div class="pipeline-step">
                <div class="step-num">6</div>
                <div class="step-body glass-card">
                    <h3>Checkpoint & Evaluation <span class="tag tag-done">Done</span></h3>
                    <p>The best evolved individual's weights are saved as <code>checkpoint-final</code>
                    (the best <em>evolved</em> adapter). The best distillation checkpoint
                    (lowest eval loss, mid-training) is saved separately as <code>checkpoint-best</code>.
                    <code>test_evolved_model.py</code> loads both, compares PPL / CE loss / fitness against
                    the base model, and prints a side-by-side generation comparison across five prompts.</p>
                    <div class="insight">checkpoint-final &gt; checkpoint-best priority Â· verdict: PASS if evo_ppl â‰¤ base_ppl</div>
                </div>
            </div>

        </div>
    </section>

    <!-- Architecture -->
    <section class="architecture" id="architecture">
        <div class="section-header">
            <h2>GPU Architecture</h2>
            <p>Designed for dual-GPU setups, with Ollama-backed teacher and student split across devices</p>
        </div>

        <div class="arch-diagram">
            <div class="gpu-container">
                <div class="gpu-box teacher glass-card">
                    <h3>GPU 0 â€” Teacher (Ollama)</h3>
                    <p>Remote qwen3.5 via Ollama API</p>
                    <p>Inference only Â· frozen weights</p>
                    <p>Hard-label CE completions</p>
                    <p>No logprobs (API limitation)</p>
                    <div class="gpu-mem">~26 GB VRAM used by Ollama</div>
                </div>

                <div class="arrow-container">
                    <div class="arrow"></div>
                    <div class="arrow-label">Completions<br>(text tokens)</div>
                    <div class="arrow"></div>
                </div>

                <div class="gpu-box student glass-card">
                    <h3>GPU 1 â€” Student</h3>
                    <p>Qwen3-1.7B + LoRA (r=16)</p>
                    <p>Distillation training Â· BF16</p>
                    <p>Evolution fitness eval</p>
                    <p>CPU â†” GPU adapter swaps</p>
                    <div class="gpu-mem">~7 GB peak during training</div>
                </div>
            </div>

            <div class="arch-note">
                <span>âš </span>
                <div>
                    <strong>Current Limitation:</strong> The teacher runs via Ollama's HTTP API rather than
                    directly on GPU 0. Ollama occupies ~26 GB on GPU 0, leaving ~5.5 GB free.
                    The student runs entirely on GPU 1 (32 GB). Evolution population weights live
                    on CPU between evaluations to avoid fragmentation.
                </div>
            </div>
        </div>
    </section>

    <!-- Results -->
    <section id="results">
        <div class="section-header">
            <h2>Training Results</h2>
            <p>Measured on WikiText-2 held-out set Â· evaluated with test_evolved_model.py</p>
        </div>

        <div style="max-width:900px;margin:0 auto 3rem;">
            <table class="runs-table">
                <thead>
                    <tr>
                        <th>Run</th>
                        <th>Steps</th>
                        <th>Gens / Pop</th>
                        <th>Base PPL</th>
                        <th>Evolved PPL</th>
                        <th>Î”PPL</th>
                        <th>Fitness</th>
                        <th>Verdict</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>run_20260224_100235</td>
                        <td>100</td>
                        <td>10 / 4</td>
                        <td class="val-base">154.34</td>
                        <td class="val-good">120.72</td>
                        <td class="val-good">âˆ’33.6</td>
                        <td class="val-good">0.00821</td>
                        <td class="val-good">PASS</td>
                    </tr>
                    <tr>
                        <td>run_20260224_131506</td>
                        <td>200</td>
                        <td>20 / 6</td>
                        <td class="val-base">154.34</td>
                        <td class="val-good">80.28</td>
                        <td class="val-good">âˆ’74.1</td>
                        <td class="val-good">0.01230</td>
                        <td class="val-good">PASS</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section-header" style="margin-top:3rem;">
            <h2>Generation Quality</h2>
            <p>Qualitative comparison â€” base vs evolved on 5 prompts (greedy decode, 60 tokens)</p>
        </div>

        <div class="fixes-grid">
            <div class="fix-card glass-card">
                <div class="fix-title">AI History prompt</div>
                <p><strong>Base:</strong> "The first artificial intelligence systems were developed in the 1950s, and the first AI systems were developed by John McCarthyâ€¦" (repetition)</p>
                <p style="margin-top:0.6rem"><strong>Evolved:</strong> "The first such attempts were made in the 1940s, when researchers like Alan Turing and others began to explore the possibility of machinesâ€¦" (coherent, accurate)</p>
            </div>
            <div class="fix-card glass-card">
                <div class="fix-title">Amazon prompt</div>
                <p><strong>Base:</strong> "a major source of oxygenâ€¦ home to a large number of species" (vague)</p>
                <p style="margin-top:0.6rem"><strong>Evolved:</strong> "home to an incredible variety of species, including over 4000 species of plants, 1000 species of birds, 1000 species of mammals" (specific, factual)</p>
            </div>
            <div class="fix-card glass-card">
                <div class="fix-title">Neural networks prompt</div>
                <p><strong>Base:</strong> "understand the underlying principlesâ€¦ the structure of the network, the role of each component" (generic)</p>
                <p style="margin-top:0.6rem"><strong>Evolved:</strong> "understanding the structure of the network, the role of each layer, and the importance of data preprocessing" (more precise, layer-specific)</p>
            </div>
        </div>
    </section>

    <!-- Bug Fixes / Internals -->
    <section id="fixes">
        <div class="section-header">
            <h2>Internals &amp; Bug Fixes</h2>
            <p>Key discoveries, root causes, and the fixes that made results possible</p>
        </div>

        <div class="fixes-grid">
            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>1</span> Uniform Soft Targets Corruption
                    <span class="badge">Critical</span>
                </div>
                <p>Ollama returns empty logprobs. KL divergence against uniform soft targets
                is always <code>TÂ² Ã— seq_len Ã— log(vocab)</code> â€” a large, constant positive value
                that actively pushes the student toward uniform predictions, destroying PPL.</p>
                <code>fix: probe logprobs at load time â†’ fall back to hard-label CE only
if teacher_outputs["has_logprobs"] is False</code>
            </div>

            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>2</span> Eval Never Fired
                    <span class="badge">Critical</span>
                </div>
                <p><code>eval_steps=100</code> default with only 20 training steps meant evaluation
                never ran, so <code>best_eval_loss</code> stayed at <code>inf</code> and
                <code>checkpoint-best</code> was never saved.</p>
                <code>fix: eval_steps = max(1, args.steps // 5)</code>
            </div>

            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>3</span> Padding Tokens in Loss
                    <span class="badge">Bug</span>
                </div>
                <p>Labels included padding token IDs, causing the model to learn to predict
                padding, inflating cross-entropy loss on padded positions.</p>
                <code>labels[attention_mask == 0] = -100  # mask padding</code>
            </div>

            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>4</span> PEFT Adapter Key Mismatch
                    <span class="badge">Bug</span>
                </div>
                <p>PEFT saves adapter weights as <code>lora_A.weight</code> but
                <code>PeftModel.state_dict()</code> uses <code>lora_A.default.weight</code>
                (adapter name "default" inserted). All 224 tensors were silently ignored â€” the
                evolved model was identical to the base model.</p>
                <code>k.replace("lora_A.weight", "lora_A.default.weight")</code>
            </div>

            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>5</span> OOM on Adapter Load
                    <span class="badge">Infrastructure</span>
                </div>
                <p><code>PeftModel.from_pretrained()</code> calls
                <code>safe_load_file(path, device="cuda:1")</code> internally, directly
                allocating on a GPU already holding ~25 GB of Ollama weights.</p>
                <code>cpu_weights = load_file(path, device="cpu")
remapped = {k: v.to(device) for k, v in ...}
model.load_state_dict(remapped, strict=False)</code>
            </div>

            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>6</span> Wrong Checkpoint Priority
                    <span class="badge">Logic</span>
                </div>
                <p><code>checkpoint-best</code> saves the lowest <em>distillation</em> eval loss
                (mid-training). <code>checkpoint-final</code> saves the best <em>evolved</em>
                individual's LoRA weights. The test script was loading the wrong one first.</p>
                <code>priority: checkpoint-final &gt; checkpoint-best</code>
            </div>

            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>7</span> Mixed-Device Population Tensors
                    <span class="badge">Gotcha</span>
                </div>
                <p><code>population.initialize_from_model()</code> copies state_dict â€” individual 0's
                tensors are on CUDA. Mutated individuals (1+) land on CPU after
                <code>torch.randn_like()</code>. Calling <code>population.diversity</code> on a
                mixed-device population raises <code>RuntimeError</code>.</p>
                <code>fix: crossover/mutate always clone to CPU first</code>
            </div>

            <div class="fix-card glass-card">
                <div class="fix-title">
                    <span>8</span> Fitness Displays as 0.0000
                    <span class="badge">Display</span>
                </div>
                <p>When PPL &gt; 10,000 (e.g., early in training before any convergence),
                <code>fitness = 1/(1+10000) â‰ˆ 0.0001</code> rounds to four decimal places as
                <code>0.0000</code>. Not a bug â€” just a display artifact of extreme perplexity.</p>
                <code>fitness = 1/(1+ppl)  # rounds at ppl > 9999</code>
            </div>
        </div>
    </section>

    <!-- Tech Stack -->
    <section id="tech">
        <div class="section-header">
            <h2>Technology Stack</h2>
            <p>Built on modern ML frameworks with evolutionary optimization at its core</p>
        </div>

        <div class="tech-grid">
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸ§¬</span>
                <h3>TIES-Merging Crossover</h3>
                <p>Academic crossover algorithm (Yadav et al., 2023). Resolves sign interference between LoRA adapters: Trim (keep top-20% by magnitude) â†’ Elect Sign (majority vote) â†’ Disjoint Merge (average only aligned weights). Prevents knowledge destruction in plain averaging.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸ”µ</span>
                <h3>SLERP Crossover</h3>
                <p>Spherical linear interpolation on LoRA A/B weight tensors. Follows geodesic paths on the weight hypersphere. Antiparallel-safe: LERP fallback when |dot| &gt; 0.9995 prevents division-by-zero NaN. Both TIES and SLERP available via <code>crossover_method</code>.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸ§ </span>
                <h3>Lamarckian Evolution</h3>
                <p>Memetic algorithm: each individual runs <code>memetic_steps</code> gradient descent steps before fitness evaluation, then writes the improved weights back to its genome. Descendants inherit learned refinements, combining the global search of evolution with gradient-local exploitation.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸŽ“</span>
                <h3>Top-K KL Distillation</h3>
                <p>Noise-free KL divergence computed exclusively over the teacher's Top-K non-zero probability tokens. Prevents the student learning "flat noise" across the remaining ~151k vocab positions. Auto-detects sparse teacher tensors; falls back to standard KL for dense teachers.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">âš¡</span>
                <h3>Async Ollama Teacher</h3>
                <p>AsyncOllamaTeacher fires all texts in a batch as concurrent aiohttp requests, eliminating GPU starvation caused by sequential synchronous HTTP calls. Drop-in replacement for OllamaTeacher with graceful degradation when logprobs are unavailable.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸ’Ž</span>
                <h3>NVIDIA 2:4 Sparsity</h3>
                <p>Hardware-accelerated structured sparsity using <code>SparseSemiStructuredTensor</code> (PyTorch â‰¥ 2.1, Ampere+). Physically compresses base-model linear layers to 2 non-zero per 4 elements â€” 2Ã— Tensor Core speedup, 50% VRAM reduction. Applied post-training as a deployment step.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸ”§</span>
                <h3>LoRA Adapters (PEFT)</h3>
                <p>Low-rank adaptation on q/k/v/o_proj with r=16, Î±=32. Only ~25 MB per individual â€” enables large population sizes without VRAM explosion. CPU-first adapter loading bypasses PEFT's direct-to-GPU allocation that OOMs on shared GPUs.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸ“Š</span>
                <h3>Live Training Monitor</h3>
                <p>watch_training.py renders a Rich terminal dashboard with distillation loss sparklines, evaluation trend, evolution fitness sparkline, computed PPL, and teacher health â€” all parsed live from the training log.</p>
            </div>
            <div class="glass-card tech-card">
                <span class="tech-icon">ðŸ§ª</span>
                <h3>Evolved Model Evaluator</h3>
                <p>test_evolved_model.py loads checkpoint-final (best evolved) vs base model, compares PPL / CE loss / fitness on WikiText-2, and prints a side-by-side generation table. CPU-first adapter injection with automatic key remapping (lora_A.weight â†’ lora_A.default.weight).</p>
            </div>
        </div>
    </section>

    <!-- Hardware -->
    <section>
        <div class="section-header">
            <h2>Hardware</h2>
            <p>Tested configuration and scaling targets</p>
        </div>
        <div class="specs-grid">
            <div class="glass-card spec-item">
                <span class="spec-icon">ðŸ–¥</span>
                <div class="spec-info">
                    <h4>Tested On</h4>
                    <p>2Ã— GPU (32 GB each) Â· GPU 0: Ollama teacher Â· GPU 1: student training + evolution eval</p>
                </div>
            </div>
            <div class="glass-card spec-item">
                <span class="spec-icon">ðŸ’»</span>
                <div class="spec-info">
                    <h4>Minimum</h4>
                    <p>1Ã— GPU 16 GB VRAM Â· Ollama on separate host or CPU inference Â· pop-size â‰¤ 4</p>
                </div>
            </div>
            <div class="glass-card spec-item">
                <span class="spec-icon">ðŸ”¥</span>
                <div class="spec-info">
                    <h4>Optimal</h4>
                    <p>2Ã— A100/H100 40â€“80 GB Â· Local teacher with logprobs Â· pop-size 16+ Â· larger models</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Roadmap -->
    <section id="roadmap">
        <div class="section-header">
            <h2>Roadmap</h2>
            <p>What's been built, what's in progress, and what's coming next</p>
        </div>

        <div class="roadmap-grid">
            <div class="glass-card roadmap-card">
                <div class="phase">Phase 1</div>
                <h3 class="done">Foundation âœ“</h3>
                <ul>
                    <li class="done">Population management (Individual, Population)</li>
                    <li class="done">Genetic operations (crossover, mutate, tournament selection)</li>
                    <li class="done">LoRA-only individuals (CPU tensors, 25 MB each)</li>
                    <li class="done">PerplexityFitness evaluation</li>
                    <li class="done">Elite preservation across generations</li>
                </ul>
            </div>

            <div class="glass-card roadmap-card">
                <div class="phase">Phase 2</div>
                <h3 class="done">Distillation âœ“</h3>
                <ul>
                    <li class="done">OllamaTeacher with logprobs probe</li>
                    <li class="done">Hard-label CE fallback (Ollama no logprobs)</li>
                    <li class="done">KDLoss (KL + CE, ready for soft targets)</li>
                    <li class="done">DistillationTrainer with eval, checkpointing</li>
                    <li class="done">Mixed precision BF16, gradient accumulation</li>
                    <li class="done">Label masking for padding tokens</li>
                    <li class="done">watch_training.py live monitor</li>
                    <li class="done">test_evolved_model.py benchmark script</li>
                </ul>
            </div>

            <div class="glass-card roadmap-card">
                <div class="phase">Phase 3</div>
                <h3 class="wip">Soft-Target KD âŸ³</h3>
                <ul>
                    <li class="done">KDLoss architecture in place</li>
                    <li class="done">Top-K KL divergence (noise-free, mask-based)</li>
                    <li class="done">Auto-detect sparse vs dense teacher tensors</li>
                    <li class="wip">Enable logprobs via vLLM or local teacher</li>
                    <li>Full KL divergence training end-to-end</li>
                    <li>Feature-level distillation (hidden states)</li>
                </ul>
            </div>

            <div class="glass-card roadmap-card">
                <div class="phase">Phase 4</div>
                <h3 class="done">Lab-Grade Evolution âœ“</h3>
                <ul>
                    <li class="done">TIES-Merging crossover (sign-interference-free)</li>
                    <li class="done">SLERP crossover with antiparallel fix</li>
                    <li class="done">Lamarckian / memetic micro-training per individual</li>
                    <li class="done">AsyncOllamaTeacher (concurrent batch requests)</li>
                    <li class="done">Top-K KL divergence loss (noise-free)</li>
                    <li class="done">NVIDIA 2:4 semi-structured sparsity (post-training)</li>
                </ul>
            </div>

            <div class="glass-card roadmap-card">
                <div class="phase">Phase 5</div>
                <h3 class="next">Neural Pruning</h3>
                <ul>
                    <li class="done">Magnitude-based unstructured pruning</li>
                    <li class="done">Gradient-based saliency pruning</li>
                    <li class="done">Structured channel/head pruning</li>
                    <li class="done">NVIDIA 2:4 physical compression</li>
                    <li class="wip">Post-pruning LoRA recovery fine-tuning</li>
                    <li>Evolve pruning threshold as hyperparameter</li>
                </ul>
            </div>

            <div class="glass-card roadmap-card">
                <div class="phase">Phase 6</div>
                <h3 class="next">Scale &amp; Deploy</h3>
                <ul>
                    <li>Merge LoRA into base model (<code>merge_and_unload()</code>)</li>
                    <li>GGUF / AWQ quantization export (~900 MB at 4-bit)</li>
                    <li>Multi-node distributed evolution</li>
                    <li>Larger student models (7B, 13B)</li>
                    <li>Domain-specific datasets (code, math, instruction)</li>
                    <li>Multi-objective fitness (PPL + speed + size)</li>
                </ul>
            </div>
        </div>

        <div class="status-grid">
            <div class="status-item"><span class="status-dot active"></span> Completed</div>
            <div class="status-item"><span class="status-dot wip"></span> In Progress</div>
            <div class="status-item"><span class="status-dot next"></span> Planned</div>
        </div>
    </section>

    <!-- Next Steps -->
    <section id="next">
        <div class="section-header">
            <h2>Next Steps to Implement</h2>
            <p>Concrete upcoming improvements, ordered by expected impact</p>
        </div>

        <div class="next-steps-grid">
            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-wip">High Priority</span></div>
                <h3>Wire a Logprobs-Capable Teacher</h3>
                <p>Top-K KL loss and AsyncOllamaTeacher are fully implemented and waiting.
                The only missing piece is a teacher that returns per-token log-probabilities.
                Deploy vLLM locally (<code>vllm serve qwen3.5</code>) or use HF
                <code>AutoModelForCausalLM</code> directly â€” both return logits.
                This unlocks the full KL divergence path and the async batch pipeline.</p>
                <div class="impact">expected: faster convergence, lower eval loss, activates Top-K KL + AsyncTeacher</div>
            </div>

            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-wip">High Priority</span></div>
                <h3>Benchmark TIES vs SLERP vs Arithmetic</h3>
                <p>TIES-Merging is now the default crossover. Run controlled ablations:
                same training seed, same pop-size and generations, swap only
                <code>crossover_method</code>. Measure final PPL and fitness diversity
                to confirm TIES outperforms the previous SLERP and arithmetic baselines.</p>
                <div class="impact">quantify TIES sign-interference improvement Â· guide future crossover choice</div>
            </div>

            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-wip">High Priority</span></div>
                <h3>Tune Lamarckian memetic_steps</h3>
                <p>Lamarckian micro-training is implemented but <code>memetic_steps=0</code>
                by default (disabled). Run experiments at memetic_steps âˆˆ {2, 5, 10} to
                find the sweet spot between per-individual training cost and fitness gain.
                Expect diminishing returns beyond ~5 steps on a 1.7B model.</p>
                <div class="impact">memetic_steps=5 estimated: 2â€“3Ã— fewer generations to same fitness</div>
            </div>

            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-next">Medium Priority</span></div>
                <h3>Larger Population &amp; More Generations</h3>
                <p>Best run: pop-size=6, 20 generations â€” fitness still improving at gen 20.
                Scale to pop-size=16, 50+ generations with TIES crossover. TIES should
                maintain higher diversity than SLERP, making larger populations more effective.</p>
                <div class="impact">pop-size=16, gen=50 + TIES â†’ estimated PPL ~60â€“65</div>
            </div>

            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-next">Medium Priority</span></div>
                <h3>LoRA â†’ Base Merge &amp; 2:4 Deploy</h3>
                <p>After evolution: <code>model.merge_and_unload()</code> to fold LoRA into
                base weights, then call <code>pruner.apply_nvidia_2_4_sparsity()</code> for
                hardware-accelerated 50% VRAM compression on Ampere+ GPUs, then export to
                GGUF/AWQ for edge deployment.</p>
                <div class="impact">merged + 2:4 + 4-bit quant â†’ ~450 MB Â· 2Ã— inference speedup on RTX GPUs</div>
            </div>

            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-next">Medium Priority</span></div>
                <h3>Adaptive Mutation Rate</h3>
                <p>Implement 1/5th-success rule or CMA-ES-style Ïƒ adaptation.
                When fitness stagnates across K generations, increase mutation scale to
                escape local optima; when improving every generation, tighten Ïƒ for
                exploitation. Complements the existing mutation_decay schedule.</p>
                <div class="impact">expected: escape plateaus, converge faster in late generations</div>
            </div>

            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-next">Medium Priority</span></div>
                <h3>Domain-Specific Training Data</h3>
                <p>Current distillation uses random Ollama completions on generic text.
                Curated corpora (code, math, instruction-following) with teacher completions
                would specialize the evolved student for targeted benchmarks rather than
                general-purpose WikiText PPL.</p>
                <div class="impact">task-specific fitness â†’ MMLU / HumanEval / GSM8K improvement</div>
            </div>

            <div class="glass-card next-card">
                <div class="priority"><span class="tag tag-next">Lower Priority</span></div>
                <h3>Multi-Objective Fitness</h3>
                <p>Replace scalar <code>1/(1+PPL)</code> with a Pareto-front over
                (PPL, tokens/sec, VRAM footprint, task accuracy). Tournament selection
                becomes non-dominated sorting (NSGA-II). Evolve toward the full
                efficiency-accuracy Pareto frontier instead of a single scalar.</p>
                <div class="impact">Pareto-optimal family of models across the speed/quality trade-off</div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="footer-links">
            <a href="#pipeline">How It Works</a>
            <a href="#results">Results</a>
            <a href="#fixes">Internals</a>
            <a href="#roadmap">Roadmap</a>
            <a href="#next">Next Steps</a>
            <a href="https://github.com/genesis-ai/genesis">GitHub</a>
        </div>
        <p class="footer-copyright">Genesis AI Evolution Laboratory Â· MIT License Â· Qwen3-1.7B student Â· qwen3.5 teacher</p>
    </footer>

    <script>
        // Neural network background nodes
        (function() {
            const container = document.getElementById('neuralBg');
            for (let i = 0; i < 35; i++) {
                const node = document.createElement('div');
                node.className = 'neural-node';
                node.style.left = Math.random() * 100 + '%';
                node.style.top = Math.random() * 100 + '%';
                node.style.animationDelay = (Math.random() * 3) + 's';
                node.style.animationDuration = (2 + Math.random() * 2) + 's';
                container.appendChild(node);
            }
        })();

        // Smooth scroll
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) target.scrollIntoView({ behavior: 'smooth' });
            });
        });
    </script>
</body>
</html>
